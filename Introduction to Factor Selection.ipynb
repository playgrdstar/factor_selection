{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor Selection ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is there a need for factor selection?\n",
    "> Adding more and more factors into your regression may make the training model's performance seem better and better. In fact, you could potentially get perfect performance if you throw enough factors into a regression model. However, such an approach is a generally a bad idea. Aside from the issues relating to collecting more data and making sure the sample size is adequate, the more important issue is with regards to to overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting happens when a model fits so well to the development or training data, that it will perform very badly once we give it any data (from the real world) that is different from the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Overfitting Example **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use data from Kaggle to see what the consequence of overfitting is. The dataset is a survey of young people on a broad range of interests and preferences, obtained from https://www.kaggle.com/miroslavsabo/young-people-survey/version/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "young_responses = pd.read_csv('young-people-survey/responses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Music</th>\n",
       "      <th>Slow songs or fast songs</th>\n",
       "      <th>Dance</th>\n",
       "      <th>Folk</th>\n",
       "      <th>Country</th>\n",
       "      <th>Classical music</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Pop</th>\n",
       "      <th>Rock</th>\n",
       "      <th>Metal or Hardrock</th>\n",
       "      <th>...</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Number of siblings</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Left - right handed</th>\n",
       "      <th>Education</th>\n",
       "      <th>Only child</th>\n",
       "      <th>Village - town</th>\n",
       "      <th>House - block of flats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>college/bachelor degree</td>\n",
       "      <td>no</td>\n",
       "      <td>village</td>\n",
       "      <td>block of flats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>college/bachelor degree</td>\n",
       "      <td>no</td>\n",
       "      <td>city</td>\n",
       "      <td>block of flats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>secondary school</td>\n",
       "      <td>no</td>\n",
       "      <td>city</td>\n",
       "      <td>block of flats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Music  Slow songs or fast songs  Dance  Folk  Country  Classical music  \\\n",
       "0    5.0                       3.0    2.0   1.0      2.0              2.0   \n",
       "1    4.0                       4.0    2.0   1.0      1.0              1.0   \n",
       "2    5.0                       5.0    2.0   2.0      3.0              4.0   \n",
       "\n",
       "   Musical  Pop  Rock  Metal or Hardrock           ...             Age  \\\n",
       "0      1.0  5.0   5.0                1.0           ...            20.0   \n",
       "1      2.0  3.0   5.0                4.0           ...            19.0   \n",
       "2      5.0  3.0   5.0                3.0           ...            20.0   \n",
       "\n",
       "   Height  Weight  Number of siblings  Gender  Left - right handed  \\\n",
       "0   163.0    48.0                 1.0  female         right handed   \n",
       "1   163.0    58.0                 2.0  female         right handed   \n",
       "2   176.0    67.0                 2.0  female         right handed   \n",
       "\n",
       "                 Education  Only child  Village - town  House - block of flats  \n",
       "0  college/bachelor degree          no         village          block of flats  \n",
       "1  college/bachelor degree          no            city          block of flats  \n",
       "2         secondary school          no            city          block of flats  \n",
       "\n",
       "[3 rows x 150 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "young_responses.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to see if we can predict the respondent's happiness in life ('Happiness in life') based on some other answers -\n",
    "- Whether he/she enjoys music ('Music')\n",
    "- Whether he/she likes to watch movies ('Movies')\n",
    "- Whether he/she likes socialising ('Fun with friends')\n",
    "- Whether he/she fears some things ('Flying', 'Storm', 'Darkness', 'Heights', 'Spiders', 'Snakes', 'Rats')\n",
    "- How are he or she is ('Daily events')\n",
    "- Whether he or she prefers money or friends ('Friends versus money')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot more dimensions than this, but let's keep to these for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "young_responses = young_responses.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_var = young_responses[['Music', 'Movies', 'Fun with friends',\n",
    "                'Flying', 'Storm', 'Darkness', 'Heights', 'Spiders', 'Snakes', 'Rats',\n",
    "               'Daily events', 'Friends versus money']]\n",
    "dependent_var = young_responses[['Happiness in life']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = independent_var.values\n",
    "y = dependent_var.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we shall move from simple linear regression, to 2nd and 3rd order polynomial regression. In-sample results (measured by the mean of squared errors or differences between the predicted and actual happiness) will improve more and more since our model is fitted closer and closer to each of the data points. But you will see out-of-sample drop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (cases, features) = (471, 12)\n",
      "Test  (cases, features) = (203, 12)\n",
      "In-sample  mean squared error 0.617\n",
      "Out-sample mean squared error 0.631\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=3)\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "\n",
    "print ('Train (cases, features) = %s' % str(X_train.shape))\n",
    "print ('Test  (cases, features) = %s' % str(X_test.shape))\n",
    "print ('In-sample  mean squared error %0.3f' % mean_squared_error(y_train,lm.predict(X_train)))\n",
    "print ('Out-sample mean squared error %0.3f' % mean_squared_error(y_test,lm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "second_order=PolynomialFeatures(degree=2, interaction_only=False)\n",
    "third_order=PolynomialFeatures(degree=3, interaction_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting closer with a 2nd order polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(cases, features) = (471, 91)\n",
      "In-sample  mean squared error 0.522\n",
      "Out-sample mean squared error 0.724\n"
     ]
    }
   ],
   "source": [
    "lm.fit(second_order.fit_transform(X_train),y_train)\n",
    "print ('(cases, features) = %s' % str(second_order.fit_transform(X_train).shape))\n",
    "print ('In-sample  mean squared error %0.3f' % mean_squared_error(y_train,lm.predict(second_order.fit_transform(X_train))))\n",
    "print ('Out-sample mean squared error %0.3f' % mean_squared_error(y_test,lm.predict(second_order.fit_transform(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting even closer with a 3rd order polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(cases, features) = (471, 299)\n",
      "In-sample  mean squared error 0.217\n",
      "Out-sample mean squared error 20.591\n"
     ]
    }
   ],
   "source": [
    "lm.fit(third_order.fit_transform(X_train), y_train)\n",
    "print ('(cases, features) = %s' % str(third_order.fit_transform(X_train).shape))\n",
    "print ('In-sample  mean squared error %0.3f' %\n",
    "mean_squared_error(y_train,lm.predict(third_order.fit_transform(X_train))))\n",
    "print ('Out-sample mean squared error %0.3f' %\n",
    "mean_squared_error(y_test,lm.predict(third_order.fit_transform(X_test))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Checking the Correlations in a Dataset **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obvious way to solve the issue of overfitting is to start getting rid of extraneous variables. One quick way of doing this is to eliminate factors that are correlated with each other. We can simply examine a correlation matrix to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 471 observations 12 features\n",
      "Validation set: 203 observations 12 features\n"
     ]
    }
   ],
   "source": [
    "print ('Training set: %i observations %i features' % (X_train.shape))\n",
    "print ('Validation set: %i observations %i features' % (X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=471, minmax=(array([ 2.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.])), mean=array([ 4.78768577,  4.62845011,  4.56900212,  1.96178344,  1.94692144,\n",
      "        2.28025478,  2.57749469,  2.79193206,  3.        ,  2.38428875,\n",
      "        3.0955414 ,  3.77707006]), variance=array([ 0.29525229,  0.45527398,  0.49682432,  1.27087681,  1.3482405 ,\n",
      "        1.61065185,  1.72962009,  2.4629986 ,  2.25106383,  1.95200795,\n",
      "        1.24829923,  1.25870714]), skewness=array([-2.96198154, -1.97141073, -1.61401196,  0.97599695,  1.09112067,\n",
      "        0.72018659,  0.40161352,  0.23739422, -0.00756769,  0.55963674,\n",
      "        0.1411506 , -0.64874969]), kurtosis=array([ 9.42609693,  4.22353256,  2.03602405,  0.08531691,  0.19819345,\n",
      "       -0.54781455, -0.96147391, -1.48197486, -1.40358096, -0.99988482,\n",
      "       -0.64169235, -0.32743757]))\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import describe\n",
    "print(describe(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "# Reference http://stackoverflow.com/questions/14391959/heatmap-in-matplotlib-with-pcolor\n",
    "# http://matplotlib.org/api/axes_api.html\n",
    "def corr_matrix_plot(data, threshold=0):\n",
    "    # returns pearson correlation coeff, rowvar means cols are the features\n",
    "    R = np.corrcoef(data, rowvar=0)\n",
    "    R[np.where(np.abs(R)<threshold)] = 0.0\n",
    "    heatmap = plt.pcolor(R, cmap=mpl.cm.coolwarm, alpha=0.8)\n",
    "    heatmap.axes.set_frame_on(False) # Set whether the axes rectangle patch is drawn\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tick_params(axis='both', which='both', bottom='off',top='off', left = 'off',right = 'off')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD/CAYAAADPJgxuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11af15518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_matrix_plot(X_train, threshold=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*See the orangy dots outside of the diagonal? A heatmap allows us to see these spots where correlation is higher straightaway.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Univariate feature selection - Stepwise selection **\n",
    "\n",
    "Other than eliminating variables with high correlation (and by tenuous inference - high collinearity), simplest way would be to use statistical tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn offers three possible tests:\n",
    "\n",
    "* The f_regression class, which works out an F-test (a statistical test for comparing different regression solutions) and a p-value (interpretable as the probability value in which we observed a difference by chance) and reveals the best features for a regression\n",
    "* The f_class, which is an Anova F-test (a statistical test for comparing differences among classes), another statistical and related method that will prove useful for classification problems\n",
    "* The Chi2 class, which is a chi-squared test (a statistical test on count data), a good choice when your problem is classification and your answer variable is a count or a binary (in every case, a positive number such as units sold or money earned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = y_train.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the f_class test\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "selector = SelectPercentile(f_classif, percentile=50)\n",
    "selector.fit(X_train, y_train)\n",
    "variable_filter = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl6TGGPyS1BiDX5IaY/BLUmMMfklqzP8Db9GsF2mYgjkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11af7a4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the scores\n",
    "plt.hist(selector.scores_, bins=50, histtype='bar')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filtered variables: 1\n",
      "Number of variables and interactions: 2\n"
     ]
    }
   ],
   "source": [
    "# picking the top features\n",
    "variable_filter = selector.scores_ > 5\n",
    "print (\"Number of filtered variables: %i\" % np.sum(variable_filter))\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "interactions = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "Xs = interactions.fit_transform(X_train[:,variable_filter])\n",
    "print (\"Number of variables and interactions: %i\" % Xs.shape[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
